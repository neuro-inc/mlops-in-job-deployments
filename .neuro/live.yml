kind: live
title: mlops-mlflow-model-deploy

volumes:
  modules:
    remote: storage:${{ project.id }}/modules
    mount: /project/modules
    local: modules
  triton_model_repo:
    remote: storage:${{ project.id }}/triton_model_repo
    mount: /tmp/project/triton_model_repo

images:
  app:
    ref: $[[ fmt("image:/{}/{}:{}", project.owner, project.id, git.sha) ]]
    dockerfile: $[[ flow.workspace ]]/Dockerfile
    context: $[[ flow.workspace ]]/
  mlflow_server:
    ref: image:/$[[ project.owner ]]/$[[ flow.project_id ]]/mlflow-server:v2
    dockerfile: $[[ flow.workspace ]]/mlflow-server.Dockerfile
    context: $[[ flow.workspace ]]/


jobs:
  app:
    image: $[[ images.app.ref ]]
    browse: true
    pass_config: true
    http_port: 8501
    volumes:
      - ${{ volumes.triton_model_repo.ref_rw }}
    env:
      MLFLOW_TRACKING_URI: ${{ params.mlflow_uri }}
      TRITON_MODEL_REPO: ${{ volumes.triton_model_repo.mount }}
      TRITON_MODEL_REPO_STORAGE: ${{ volumes.triton_model_repo.remote }}
    params:
      mlflow_uri: https://mlops-pytorch-mlflow-trito-mlflow-server--yevheniisemendiak.jobs.green-hgx-1.org.neu.ro

  webdav:
    action: gh:neuro-actions/webdav_server@v1.0.0
    args:
      volume_remote: ${{ volumes.triton_model_repo.remote }}
      job_lifespan: 30d